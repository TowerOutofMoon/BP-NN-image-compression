{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94593d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0379a716",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 测试数据集\n",
    "# X, y = datasets.make_moons(n_samples=100, noise=0.2, random_state=100)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9f9ac83",
   "metadata": {
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self,input_nodes, output_nodes, \n",
    "                 activation=None, \n",
    "                 weights=None, bias=None):\n",
    "        \"\"\"\n",
    "        input_nodes: 输入节点数 \n",
    "        output_nodes: 输出节点数         \n",
    "        activation: 激活函数      \n",
    "        weights: 权值      \n",
    "        bias: 偏置\n",
    "    \"\"\"\n",
    "        \n",
    "        self.weights = np.random.randn(input_nodes,output_nodes) * np.sqrt(1 / output_nodes) # Xavier初始值 \n",
    "        self.bias = np.random.normal(0,0.1,output_nodes) # 均值为0，标准差为0.1的高斯分布\n",
    "        self.activation = activation\n",
    "        self.activation_output = None     \n",
    "        self.error = None  # 用于计算当前层的 delta 变量的中间变量 \n",
    "        self.delta = None  # 记录当前层的 delta 变量，用于计算梯度 \n",
    "    \n",
    "    def activate(self, X):\n",
    "        # forward\n",
    "        r = np.dot(X, self.weights) + self.bias\n",
    "        self.activation_output = self.apply_activation(r) \n",
    "        return self.activation_output\n",
    "    \n",
    "    def apply_activation(self, r): \n",
    "        # 计算激活函数的输出\n",
    "        if self.activation is None:\n",
    "            return r\n",
    "        if self.activation == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-r))\n",
    "        elif self.activation == 'relu':\n",
    "            return np.maximum(r, 0)        \n",
    "        elif self.activation == 'tanh':\n",
    "            return np.tanh(r)\n",
    "        return r\n",
    "    \n",
    "    def apply_activation_diff(self, r):\n",
    "        # 计算激活函数的导数\n",
    "        if self.activation is None:\n",
    "            return np.ones_like(r)\n",
    "        # Sigmoid       \n",
    "        elif self.activation == 'sigmoid': \n",
    "            return r * (1 - r)\n",
    "        # ReLU\n",
    "        elif self.activation == 'relu':             \n",
    "            grad = np.array(r, copy=True)             \n",
    "            grad[r > 0] = 1             \n",
    "            grad[r <= 0] = 0             \n",
    "            return grad\n",
    "        # tanh      \n",
    "        elif self.activation == 'tanh':             \n",
    "            return 1 - r ** 2 \n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0117f31",
   "metadata": {
    "code_folding": [
     4,
     13
    ]
   },
   "outputs": [],
   "source": [
    "class NeutralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = [] # 网络层\n",
    "    \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # 前向传播\n",
    "        for layer in self.layers:\n",
    "            X = layer.activate(X)\n",
    "        return X\n",
    "    \n",
    "    def mean_squared_loss(self, X_train, y_train):\n",
    "        square =  np.square(y_train - self.forward(X_train))\n",
    "        length = len(square.flatten())\n",
    "        total_loss = np.sum(square)\n",
    "        return total_loss / length\n",
    "    \n",
    "    def BP(self, X, y, lr):\n",
    "        # 反向传播算法\n",
    "        # 向前计算，得到最终输出值\n",
    "        output = self.forward(X)\n",
    "        for i in reversed(range(len(self.layers))): \n",
    "            layer = self.layers[i]\n",
    "            if layer == self.layers[-1]: # 如果是输出层\n",
    "                layer.error = y - output\n",
    "                # delta = (o - t) * diff\n",
    "                layer.delta = layer.error * layer.apply_activation_diff(output)\n",
    "            else: \n",
    "                next_layer = self.layers[i + 1] \n",
    "                # 使用上一层的delta\n",
    "                layer.error = np.dot(next_layer.weights, next_layer.delta)\n",
    "                layer.delta = layer.error * layer.apply_activation_diff(layer.activation_output)\n",
    "        \n",
    "        # 更新权重\n",
    "        for i in range(len(self.layers)):\n",
    "            layer = self.layers[i]\n",
    "            # 输入数据或者上一层数据的输出\n",
    "            x = X if i == 0 else self.layers[i-1].activation_output\n",
    "            # 限制其至少为2维进行运算\n",
    "            ahead_layer_output = np.atleast_2d(x)\n",
    "            # 梯度下降\n",
    "            # w_descend = delta * output * learning_rate\n",
    "            layer.weights += layer.delta * ahead_layer_output.T * lr\n",
    "            # print(layer.delta.shape, ahead_layer_output.shape)\n",
    "            \n",
    "            # b_descend = delta * learning_rate\n",
    "            layer.bias += layer.delta * lr\n",
    "    \n",
    "    def train(self, X_train, y_train, lr, max_epochs):\n",
    "        # 网络训练函数\n",
    "        # one-hot 编码：二分类\n",
    "        # y_onehot = np.zeros((y_train.shape[0], 2)) \n",
    "       #  y_onehot[np.arange(y_train.shape[0]), y_train] = 1\n",
    "        mses = [] \n",
    "        for i in range(max_epochs):         \n",
    "            for j in range(len(X_train)):  # 一次训练一个样本                 \n",
    "                self.BP(X_train[j],  y_train[j], lr)             \n",
    "                # 打印出 MSE Loss                 \n",
    "                mse = self.mean_squared_loss(X_train,y_train)                \n",
    "                mses.append(mse)                 \n",
    "            print('Epoch: %d, MSE: %f' % (i+1, float(mse)))\n",
    "                  \n",
    "    # 如果是分类问题，则计算准确度\n",
    "    def accuracy(self, y_predict, y_test): \n",
    "        return np.sum(y_predict == y_test) / len(y_test)\n",
    "    \n",
    "    def predict(self, X_predict):\n",
    "        return self.forward(X_predict)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb72a149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y_onehot = np.zeros((y_train.shape[0], 2)) \n",
    "# y_onehot[np.arange(y_train.shape[0]), y_train] = 1\n",
    "# y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74e7c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.train(X_train, X_test, y_train, y_test, 0.1, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00110779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.predict(X_test) == y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5c8e2c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 读取图片数据集\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "073485d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_batch= unpickle('./cifar-10-batches-py/test_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de9066f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a438f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 包含rgb三个通道各1024位，总共3072位，10000个数据\n",
    "# print(test_batch[b'data'].shape)\n",
    "# 10000个数据的标签,类别为0-9\n",
    "# print(len(test_batch[b'labels']) )\n",
    "# batch的名称:test batch, batch1, batch2\n",
    "# print(test_batch[b'batch_label'])\n",
    "# 图片名称\n",
    "# print(test_batch[b'filenames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "122239c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = unpickle('./cifar-10-batches-py/data_batch_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "696af390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = batch[b'data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ef1b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据保存为jpg图片\n",
    "# for i in range(50):\n",
    "#     image = data[i]\n",
    "#     r_channel = image[:1024].reshape(32,32)\n",
    "#     g_channel = image[1024:2048].reshape(32,32)\n",
    "#     b_channel = image[2048:].reshape(32,32)\n",
    "#     result_img = np.ones((32, 32, 3), dtype=np.uint8)\n",
    "#     result_img[:,:,0] = r_channel\n",
    "#     result_img[:,:,1] = g_channel\n",
    "#     result_img[:,:,2] = b_channel\n",
    "#     cv2.imwrite('./images/'+str(i)+'.jpg',result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5120024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Expand(channel,block_size):\n",
    "    Height = channel.shape[0]\n",
    "    Width = channel.shape[1]\n",
    "    Max = Height if Height > Width else Width\n",
    "    if(Height % block_size == 0 and Width % block_size == 0):\n",
    "        return channel\n",
    "    else:\n",
    "        # 计算扩充块的大小\n",
    "        if(Max % block_size == 0): N = Max\n",
    "        else: N = block_size * ((int)(Max / block_size) + 1)\n",
    "        expand_channel = np.zeros((N,N))\n",
    "        for i in range(Height):\n",
    "            for j in range(Width):\n",
    "                expand_channel[i][j] = channel[i][j]\n",
    "        return expand_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b553728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Divide(channel,block_size):\n",
    "    Height = channel.shape[0]\n",
    "    Width = channel.shape[1]\n",
    "    if Height != Width: return \n",
    "    else: \n",
    "        num = (int) (Height / block_size)\n",
    "        train_data = np.zeros((num*num,block_size*block_size))\n",
    "        # 按块处理\n",
    "        for i in range(num):\n",
    "            for j in range(num):\n",
    "                    block = channel[j * block_size : (j + 1) * block_size, \n",
    "                                    i * block_size : (i + 1) * block_size].flatten()\n",
    "                    col = (int)(i * num + j)\n",
    "                    train_data[col,:] = block\n",
    "        return train_data / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4038c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveNN(train_data, n_hidden,num_epochs):\n",
    "    # 获取训练后隐藏层的输出,输出层的权重和偏置\n",
    "    # print(train_data.shape) (121,256) (nums,features)\n",
    "    n_nums = train_data.shape[0]\n",
    "    n_features = train_data.shape[1]\n",
    "    nn = NeuralNetwork() # 初始化神经网络模型\n",
    "    # 构建神经网络\n",
    "    nn.add_layer(Layer(n_features,n_hidden,'relu')) # 非线性层\n",
    "    nn.add_layer(Layer(n_hidden,n_features)) # 线性层\n",
    "    # 训练\n",
    "    nn.train(train_data,train_data,0.1,num_epochs)\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10a914a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reback(train_data,Height,Width):\n",
    "    num = (int) (np.sqrt(train_data.shape[0])) # 块个数\n",
    "    block_size = (int) (np.sqrt(train_data.shape[1])) # 块大小\n",
    "    width = height = block_size * num # 扩充后的宽高\n",
    "    # 还原\n",
    "    expand_channel = np.zeros((width,height))\n",
    "    for i in range(num):\n",
    "        for j in range(num):\n",
    "            block = train_data[i * num + j, :].reshape(block_size,block_size)\n",
    "            expand_channel[j * block_size : (j + 1) * block_size, \n",
    "                    i * block_size : (i + 1) * block_size] = block\n",
    "    # 去除扩充后的数据\n",
    "    channel = np.zeros((Height,Width))\n",
    "    for i in range(Height):\n",
    "        for j in range(Width):\n",
    "           channel[i][j] = expand_channel[i][j]\n",
    "    return channel * 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cc652b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compress(path,block_size,n_hidden,num_epochs):\n",
    "    # 1. 读取图片\n",
    "    img = cv2.imread(path)\n",
    "    Height = img[:,:,0].shape[0]\n",
    "    Width = img[:,:,0].shape[1]\n",
    "    # 2. 分别处理rgb三个通道\n",
    "    NN = [] # 三个通道对应的三个BP神经网络信息\n",
    "    for i in range(3):\n",
    "        channel = img[:,:,i] # 一个通道\n",
    "        # 3. 通道扩充\n",
    "        channel = Expand(channel,block_size)\n",
    "        # 4. 通道分块\n",
    "        train_data = Divide(channel,block_size)\n",
    "        # 5. 训练神经网络并保存\n",
    "        NN.append(SaveNN(train_data, n_hidden,num_epochs))\n",
    "    return NN,Height,Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55e3a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Depress(path,NN,Height,Width):\n",
    "    # 原图片\n",
    "    img = np.zeros((Height,Width,3))\n",
    "    # 获取参数\n",
    "    # 1.分别处理3个神经网络\n",
    "    for i in range(3):\n",
    "        nn = NN[i]\n",
    "        # 隐藏层\n",
    "        hidden_layer = nn.layers[0]\n",
    "        # 输出层\n",
    "        output_layer = nn.layers[1]\n",
    "        # 隐藏层输出\n",
    "        compress_channel = hidden_layer.activation_output\n",
    "        # 输出层的w和b\n",
    "        hidden_w, hidden_b = [output_layer.weights,output_layer.bias]\n",
    "        # 计算对应通道分块之后的训练数据\n",
    "        train_data = (np.dot(compress_channel,hidden_w) + hidden_b)\n",
    "        # 对分块的通道进行还原并储存\n",
    "        img[:,:,i] = Reback(train_data,Height,Width)\n",
    "    cv2.imwrite(path,img)\n",
    "    print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "47f31946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate(origin_path, compress_path):\n",
    "    stats1 = os.stat(origin_path)\n",
    "    stats2 = os.stat(compress_path)\n",
    "    img1 = cv2.imread(origin_path).astype(np.float32)\n",
    "    img2 = cv2.imread(compress_path).astype(np.float32)\n",
    "    row = img1.shape[0]\n",
    "    col = img1.shape[1]\n",
    "    rate = stats2.st_size / stats1.st_size\n",
    "    mse = np.sum(((img1 - img2).flatten()) ** 2)\n",
    "    psnr = 10 * np.log10(3 * row * col * 255**2 / mse)\n",
    "    print('rate: %f' % rate)\n",
    "    print('psnr: %f' % psnr)\n",
    "    print('mse: %f' % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f28c945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用sklearn内置的BP算法实现压缩\n",
    "def bpid(read_path,write_path,block_size,hidden_layer_sizes,max_iter):\n",
    "    # 1. 读取图片\n",
    "    img = cv2.imread(read_path)\n",
    "    Height = img[:,:,0].shape[0]\n",
    "    Width = img[:,:,0].shape[1]\n",
    "    MAX = Height if Height > Width else Width\n",
    "    if MAX % block_size == 0: \n",
    "        nums = MAX / block_size\n",
    "    else:\n",
    "        nums = MAX / block_size + 1\n",
    "    # 2. 分别处理rgb三个通道\n",
    "    predicts = []\n",
    "    for i in range(3):\n",
    "        channel = img[:,:,i] # 一个通道\n",
    "        # 3. 通道扩充\n",
    "        channel = Expand(channel,block_size)\n",
    "        # 4. 通道分块\n",
    "        train_data = Divide(channel,block_size)\n",
    "        # 5. 训练神经网络并保存结果\n",
    "        mlp = MLPRegressor(hidden_layer_sizes=hidden_layer_sizes,\n",
    "                           max_iter=max_iter)\n",
    "        mlp.fit(train_data,train_data)\n",
    "        predicts.append(mlp.predict(train_data))\n",
    "    # 6. 还原\n",
    "    I = np.zeros((Height,Width,3))\n",
    "    for i in range(3):\n",
    "        I[:,:,i] = Reback(predicts[i],Height,Width)\n",
    "    cv2.imwrite(write_path,I)\n",
    "    print('success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dc68594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN,Height,Width = Compress('./test-images/wenwen.jpg',\n",
    "#                            block_size=4,\n",
    "#                            n_hidden=10,\n",
    "#                            num_epochs=50)\n",
    "# Depress('./test-images/compress-wenwen.jpg',NN,Height,Width)\n",
    "# Evaluate('./test-images/wenwen.jpg','./test-images/compress-wenwen.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee791ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN,Height,Width = Compress('./test-images/Curry/Curry1024.png',\n",
    "#                            block_size=4,\n",
    "#                            n_hidden=10,\n",
    "#                            num_epochs=50)\n",
    "# Depress('./test-images/Curry/Compressed/Curry1024',NN,Height,Width)\n",
    "# Evaluate('./test-images/Curry/Curry1024.png','./test-images/Curry/Compressed/Curry1024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c55b6395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success!\n",
      "rate: 1.337001\n",
      "psnr: 26.431877\n",
      "mse: 12003547.000000\n"
     ]
    }
   ],
   "source": [
    "bpid('./test-images/wenwen.jpg',\n",
    "     './test-images/perfect-wenwen.jpg',\n",
    "     2,hidden_layer_sizes=(14),max_iter=500)\n",
    "Evaluate('./test-images/wenwen.jpg',\n",
    "         './test-images/perfect-wenwen.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f9ab190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "aa007f36",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success!\n",
      "rate: 0.942138\n",
      "psnr: 76.682149\n",
      "mse: 4741.000000\n",
      "该程序耗时: 19.6575 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "bpid('./test-images/Curry/Curry1024.png',\n",
    "     './test-images/Curry/Compressed/Curry1024.png',\n",
    "     2,hidden_layer_sizes=(64),max_iter=500)\n",
    "toc = time.perf_counter()\n",
    "Evaluate('./test-images/Curry/Curry1024.png',\n",
    "         './test-images/Curry/Compressed/Curry1024.png')\n",
    "print(f\"该程序耗时: {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3c32488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_w = np.max(hidden_w)\n",
    "# max_b = np.max(hidden_b)\n",
    "# max_red = np.max(compress_red_channel)\n",
    "# min_w = np.min(hidden_w)\n",
    "# min_b = np.min(hidden_b)\n",
    "# min_red = np.min(compress_red_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb440269",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def NormalizationParam(*params):\n",
    "    many = []\n",
    "    for param in params:\n",
    "        max_value = np.max(param)\n",
    "        min_value = np.min(param)\n",
    "        param = ((param - min_value) / (max_value - min_value)) * 63.0\n",
    "        many.append(param)\n",
    "    return many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cea3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeNormalization(params):\n",
    "    many = []\n",
    "    for [maxp,minp,param] in params:\n",
    "        param = param / 63.0\n",
    "        param = param * (maxp - minp) + minp\n",
    "        many.append(param)\n",
    "    return many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0612d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "# hidden_w,hidden_b,compress_red_channel = NormalizationParam(hidden_w,hidden_b,compress_red_channel)\n",
    "# hidden_w,hidden_b,compress_red_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "247fc986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 反归一化\n",
    "# params = [[max_w,min_w,hidden_w],[max_b,min_b,hidden_b],[max_red,min_red,compress_red_channel]]\n",
    "# hidden_w,hidden_b,compress_red_channel = DeNormalization(params)\n",
    "# hidden_w,hidden_b,compress_red_channel\n",
    "# red_channel = np.dot(compress_red_channel,hidden_w) + hidden_b\n",
    "# red_channel,pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
