{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad4d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b2fd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 163, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dragon = cv2.imread('./test-images/wenwen.jpg')\n",
    "dragon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4afb2788",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def Expand(channel,block_size):\n",
    "    Height = channel.shape[0]\n",
    "    Width = channel.shape[1]\n",
    "    Max = Height if Height > Width else Width\n",
    "    if(Height % block_size == 0 and Width % block_size == 0):\n",
    "        return channel\n",
    "    else:\n",
    "        # 计算扩充块的大小\n",
    "        if(Max % block_size == 0): N = Max\n",
    "        else: N = block_size * ((int)(Max / block_size) + 1)\n",
    "        expand_channel = np.zeros((N,N))\n",
    "        print(expand_channel.shape)\n",
    "        for i in range(Height):\n",
    "            for j in range(Width):\n",
    "                expand_channel[i][j] = channel[i][j]\n",
    "        return expand_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb2fe7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[204, 203, 200, ..., 185, 185, 185],\n",
       "       [202, 203, 201, ..., 185, 185, 185],\n",
       "       [199, 200, 201, ..., 186, 186, 186],\n",
       "       ...,\n",
       "       [ 70,  68,  69, ...,  77,  77,  77],\n",
       "       [ 70,  68,  68, ...,  71,  70,  69],\n",
       "       [ 70,  69,  67, ...,  77,  77,  76]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel = dragon[:,:,0]\n",
    "channel.shape\n",
    "channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12cf31e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 176)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(176, 176)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand = Expand(channel,16)\n",
    "expand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45549324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('./test-images/expand-wenwen.jpg',expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e55659d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Divide(channel,block_size):\n",
    "    Height = channel.shape[0]\n",
    "    Width = channel.shape[1]\n",
    "    if Height != Width: return \n",
    "    else: \n",
    "        num = (int) (Height / block_size)\n",
    "        train_data = np.zeros((num*num,block_size*block_size))\n",
    "        # 按块处理\n",
    "        for i in range(num):\n",
    "            for j in range(num):\n",
    "                    block = channel[j * block_size : (j + 1) * block_size, \n",
    "                                    i * block_size : (i + 1) * block_size].flatten()\n",
    "                    col = (int)(i * num + j)\n",
    "                    train_data[col,:] = block\n",
    "        return train_data / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "141709f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reback(train_data,block_size,num,Height,Width):\n",
    "    width = height = block_size * num # 扩充后的宽高\n",
    "    # 还原\n",
    "    expand_channel = np.zeros((width,height))\n",
    "    for i in range(num):\n",
    "        for j in range(num):\n",
    "            block = train_data[i * num + j, :].reshape(block_size,block_size)\n",
    "            expand_channel[j * block_size : (j + 1) * block_size, \n",
    "                    i * block_size : (i + 1) * block_size] = block\n",
    "    # 去除扩充后的数据\n",
    "    channel = np.zeros((Height,Width))\n",
    "    for i in range(Height):\n",
    "        for j in range(Width):\n",
    "           channel[i][j] = expand_channel[i][j]\n",
    "    return channel * 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11413fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 256)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = Divide(expand,16)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e62e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Reback(train_data,16,11,166,163)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a8d83a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([202., 203., 201., 200., 198., 197., 197., 195., 194., 193., 179.,\n",
       "        157., 139., 136., 157., 180.]),\n",
       " array([202., 203., 201., 200., 198., 197., 197., 195., 194., 193., 179.,\n",
       "        157., 139., 136., 157., 180.]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0,16:32]*255,r[1,0:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf967014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(((np.array([[[1,2],[2,2]],\n",
    "          [[1,1],[1,1]]]) - np.array([[[1,1],[1,1]],\n",
    "                                      [[2,2],[2,2]]])).flatten()) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa0cdd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3b1accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./test-images/wenwen.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e51158f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "test_data  = scaler.fit(train_data)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100,50,20),max_iter=500)\n",
    "mlp.fit(train_data,train_data)\n",
    "predict = mlp.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "297b8896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1431777 ,  1.14512206,  1.12523821, ...,  1.23944843,\n",
       "         1.32543837,  1.26636011],\n",
       "       [ 1.08254895,  1.09998369,  1.15570109, ...,  1.3680153 ,\n",
       "         1.32543837,  1.33114515],\n",
       "       [ 1.23412084,  1.20530656,  1.06431246, ...,  1.1623083 ,\n",
       "         1.32543837,  1.48662924],\n",
       "       ...,\n",
       "       [-0.06939738, -0.20902923, -0.96146878, ..., -1.31903239,\n",
       "        -1.32458784, -1.33799844],\n",
       "       [-0.84241399, -0.87105875, -0.93100591, ..., -1.31903239,\n",
       "        -1.32458784, -1.33799844],\n",
       "       [-0.59989897, -0.67545912, -0.8091544 , ..., -1.31903239,\n",
       "        -1.32458784, -1.33799844]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29478fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.200015825399466"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(predict,train_data)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7db5483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.11444005,  0.73772489,  1.02281497, ...,  0.73805523,\n",
       "          1.23729837,  0.83152273],\n",
       "        [ 0.99638383,  1.12673055,  0.94107374, ...,  1.2581879 ,\n",
       "          1.13360079,  1.03559982],\n",
       "        [ 0.33338885,  0.19472625,  0.21973767, ...,  0.98189032,\n",
       "          0.45322551,  1.0348922 ],\n",
       "        ...,\n",
       "        [-0.78110518, -0.98231086, -0.65485159, ..., -1.44505588,\n",
       "         -1.42236056, -1.25851745],\n",
       "        [-0.71097569, -1.03795481, -0.61293092, ..., -1.4350371 ,\n",
       "         -1.32380592, -1.1927388 ],\n",
       "        [-0.96731143, -0.91847836, -0.92474328, ..., -1.6656094 ,\n",
       "         -1.57032803, -1.29900505]]),\n",
       " array([[ 1.1431777 ,  1.14512206,  1.12523821, ...,  1.23944843,\n",
       "          1.32543837,  1.26636011],\n",
       "        [ 1.08254895,  1.09998369,  1.15570109, ...,  1.3680153 ,\n",
       "          1.32543837,  1.33114515],\n",
       "        [ 1.23412084,  1.20530656,  1.06431246, ...,  1.1623083 ,\n",
       "          1.32543837,  1.48662924],\n",
       "        ...,\n",
       "        [-0.06939738, -0.20902923, -0.96146878, ..., -1.31903239,\n",
       "         -1.32458784, -1.33799844],\n",
       "        [-0.84241399, -0.87105875, -0.93100591, ..., -1.31903239,\n",
       "         -1.32458784, -1.33799844],\n",
       "        [-0.59989897, -0.67545912, -0.8091544 , ..., -1.31903239,\n",
       "         -1.32458784, -1.33799844]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict,train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bb427ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Reback(train_data,16,11,166,163)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34ee6304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 291.51031459,  292.00612585,  286.93574385, ...,  218.07373632,\n",
       "         222.94440991,  228.67549381],\n",
       "       [ 290.14820967,  301.28781071,  297.39765431, ...,  223.19343434,\n",
       "         231.66395376,  236.04195751],\n",
       "       [ 290.26341874,  305.97813707,  309.45718695, ...,  237.81862691,\n",
       "         249.29321098,  250.44018639],\n",
       "       ...,\n",
       "       [-231.03412387, -232.0334432 , -209.45086707, ..., -202.24831879,\n",
       "        -195.35936197, -177.87011329],\n",
       "       [-223.25242866, -230.7129077 , -239.56474039, ..., -219.16442263,\n",
       "        -222.5645534 , -235.42310107],\n",
       "       [-204.43833374, -230.77378995, -243.19270344, ..., -176.8124134 ,\n",
       "        -197.88860981, -205.90224244]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a68fedf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('./test-images/test-wenwen.jpg',r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7396fa67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
